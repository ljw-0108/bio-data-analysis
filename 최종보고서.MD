# 심장질환 예측 프로젝트 최종보고서

## 1. 프로젝트 소개

본 프로젝트는 개인의 기초 건강 정보를 활용하여 향후 10년 이내 심장질환 발생 여부를 예측하는 머신러닝 및 딥러닝 기반 예측 모델을 개발하는 것을 목표로 합니다. 특히, 조기 진단 및 예방이 중요한 심장질환 분야에서 적은 검사 항목만으로도 높은 정확도의 예측 결과를 제공함으로써 의료진의 보조 의사결정을 지원하고, 환자의 질환 관리 효율성을 향상시키는 것을 지향합니다.

목표 1: 환자 개인별 정보를 기반으로 심장질환 발생 확률을 예측하여 임상의가 참고할 수 있는 근거 자료 제공

목표 2: 데이터 기반 예측 모델을 통해 기존 경험적 진단 방식을 보완하고, 빠르고 객관적인 예측 결과 도출

목표 3: AUC 0.90 이상 달성 및 모델 해석 가능성 확보를 통해 실제 의료 현장 적용 가능성 검증

본 보고서에서는 해당 목표를 달성하기 위해 사용한 데이터셋의 특성과 전처리 과정, 다양한 모델 구조, 평가 결과를 종합적으로 제시하며, 향후 개선 방향을 함께 논의합니다.

## 2. 주제 관련 배경

### 2.1 심장질환의 중요성

* 심장질환은 전 세계 주요 사망 원인 중 하나로, 조기 진단 및 예방이 매우 중요합니다.
* 고령화와 서구화된 식습관, 운동 부족 등으로 인해 발생 위험이 증가하는 추세입니다.

### 2.2 데이터 기반 예측의 필요성

* 전통적으로 의사와 전문가의 경험적 판단에 의존했던 진단 과정을 **데이터 기반 판단**으로 보완함으로써, 더 객관적이고 빠른 예측이 가능해집니다.
* **머신러닝/딥러닝** 기술을 활용하여, 비교적 적은 검사 항목만으로도 환자의 심장질환 위험도를 효율적으로 산출할 수 있습니다.

## 3. 데이터셋 소개

### 3.1 데이터 출처 및 구성

* **데이터 출처**: UCI Machine Learning Repository의 Cleveland Heart Disease 데이터셋 (heart.csv)
* **샘플 수**: 총 303개 환자
* **피처 수**: 14개 컬럼 (13개 입력 피처 + 1개 타깃 컬럼)

### 3.2 주요 컬럼 설명

| 컬럼 이름            | 설명                           | 값 범위/형식                   |
| ---------------- | ---------------------------- | ------------------------- |
| `Age`            | 환자 나이 (세)                    | 29\~77                    |
| `Sex`            | 성별 (0=여성, 1=남성)              | 0, 1                      |
| `ChestPainType`  | 흉통 유형 (4가지 범주형)              | `TA`, `ATA`, `NAP`, `ASY` |
| `RestingBP`      | 안정 시 혈압 (mm Hg)              | 94\~200                   |
| `Cholesterol`    | 혈중 콜레스테롤 (mg/dL)             | 126\~564                  |
| `FastingBS`      | 공복 혈당 (0=정상, 1=당뇨 의심)        | 0, 1                      |
| `RestingECG`     | 안정 시 심전도 결과 (범주형)            | `Normal`, `ST`, `LVH`     |
| `MaxHR`          | 최대 심박수 (bpm)                 | 71\~202                   |
| `ExerciseAngina` | 운동 중 협심증 여부 (0=없음, 1=있음)     | 0, 1                      |
| `Oldpeak`        | 운동 후 ST 분절 하강 정도 (mm)        | 0.0\~6.2                  |
| `ST_Slope`       | 운동 중 ST 기울기 (범주형)            | `Up`, `Flat`, `Down`      |
| `HeartDisease`   | **타깃**: 심장질환 유무 (0=정상, 1=질환) | 0, 1                      |

### 3.3 데이터 분포 요약

* 정상(0) 136명(45.5%), 질환(1) 167명(54.5%)로 약간의 불균형이 존재합니다.
* 결측치는 없으며, 수치형 피처들 간 상관관계를 통해 일부 상관도가 높은 특성 조합을 확인할 수 있습니다.

## 4. 전처리 과정

### 4.1 결측치 및 이상치 처리

* 본 데이터셋에는 결측치가 없으므로 별도 결측치 대체 작업 없이 진행했습니다.
* 이상치는 박스플롯으로 일부 확인하였으나, 전체 모델 학습상 큰 영향을 미치지 않아 보존했습니다.

### 4.2 피처 타입 구분 및 변환

* **숫자형 피처**: `Age`, `RestingBP`, `Cholesterol`, `MaxHR`, `Oldpeak` 등 5개
* **범주형 피처**: `Sex`, `ChestPainType`, `FastingBS`, `RestingECG`, `ExerciseAngina`, `ST_Slope` 등 6개

1. **숫자형 피처**:

   * 중앙값(`median`)으로 결측치(impute) 처리
   * **StandardScaler**로 표준화 (평균 0, 분산 1)

2. **범주형 피처**:

   * 최빈값(`most_frequent`)으로 결측치 대체
   * **One-Hot Encoding**을 적용하여 개별 더미 변수로 변환

```python
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer

num_cols = ['Age', 'RestingBP', 'Cholesterol', 'MaxHR', 'Oldpeak']
cat_cols = ['Sex', 'ChestPainType', 'FastingBS', 'RestingECG', 'ExerciseAngina', 'ST_Slope']

num_pipeline = Pipeline([
    ('imputer', SimpleImputer(strategy='median')),
    ('scaler', StandardScaler())
])
cat_pipeline = Pipeline([
    ('imputer', SimpleImputer(strategy='most_frequent')),
    ('onehot', OneHotEncoder(handle_unknown='ignore'))
])

preprocessor = ColumnTransformer([
    ('num', num_pipeline, num_cols),
    ('cat', cat_pipeline, cat_cols)
])
```

### 4.3 학습/검증 데이터 분리

* 전체 데이터 303개 중 \*\*80%\*\*를 학습셋(242개), \*\*20%\*\*를 검증셋(61개)으로 분리
* `train_test_split(..., stratify=y, random_state=42)`를 사용하여 클래스 비율을 유지하면서 분할

## 5. 모델 구조

### 5.1 머신러닝 모델

1. **로지스틱 회귀 (Logistic Regression)**

   * 선형 결정 경계를 사용하여 분류
   * 기본 파라미터 설정, 최대 반복 횟수 1000
2. **랜덤 포레스트 (Random Forest)**

   * 100개 트리를 사용한 앙상블 모델
   * 단일 의사결정트리(tree)의 과적합(Overfitting) 문제를 완화

모델 학습 전 파이프라인:

```python
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier

pipe_lr = Pipeline([
    ('pre', preprocessor),
    ('clf', LogisticRegression(max_iter=1000))
])

pipe_rf = Pipeline([
    ('pre', preprocessor),
    ('clf', RandomForestClassifier(n_estimators=100, random_state=42))
])
```

#### 5.1.1 k‑Fold 교차검증

* **5‑Fold CV**를 적용하여 모델의 일반화 성능을 평가
* `cross_val_score(pipe, X, y, cv=5, scoring='roc_auc')`를 사용하여 평균 AUC와 표준편차 계산

```python
from sklearn.model_selection import cross_val_score

scores_lr = cross_val_score(pipe_lr, X, y, cv=5, scoring='roc_auc', n_jobs=-1)
scores_rf = cross_val_score(pipe_rf, X, y, cv=5, scoring='roc_auc', n_jobs=-1)
print(f"LogisticRegression 5-Fold CV AUC: {scores_lr.mean():.3f} (std: {scores_lr.std():.3f})")
print(f"RandomForest      5-Fold CV AUC: {scores_rf.mean():.3f} (std: {scores_rf.std():.3f})")
```

### 5.2 딥러닝 모델 (MLP)

* 전처리된 입력 차원(`X_train_np.shape[1]`)에 맞춰 **다층 퍼셉트론(Multi‑Layer Perceptron)** 구성
* 구조: 입력층 → 은닉층1(64개 노드, ReLU) → 드롭아웃(0.3) → 은닉층2(32개 노드, ReLU) → 출력층(1개 노드, Sigmoid)
* 손실함수: `binary_crossentropy`, 최적화: `Adam`, 지표: `AUC`

```python
import tensorflow as tf
from tensorflow.keras import layers, models

X_train_np = preprocessor.fit_transform(X_train)
X_val_np = preprocessor.transform(X_val)

dl_model = models.Sequential([
    layers.Input(shape=(X_train_np.shape[1],)),
    layers.Dense(64, activation='relu'),
    layers.Dropout(0.3),
    layers.Dense(32, activation='relu'),
    layers.Dense(1, activation='sigmoid')
])
dl_model.compile(
    optimizer='adam',
    loss='binary_crossentropy',
    metrics=[tf.keras.metrics.AUC(name='auc')]
)
dl_model.summary()

history = dl_model.fit(
    X_train_np, y_train,
    validation_data=(X_val_np, y_val),
    epochs=30, batch_size=32
)
```

## 6. 레퍼런스의 개선점

* **단일 성능 지표(AUC) 의존**에서 벗어나, Precision‑Recall Curve, F1‑Score 등 **다양한 평가 지표**를 함께 제시해야 합니다.
* **클래스 불균형 처리**: 단순 Stratified 분할만으로는 소수 클래스(정상 vs 질환) 불균형을 완전히 해결하지 못하므로, SMOTE(오버샘플링), 언더샘플링, `class_weight` 조정 등의 기법을 도입하면 재현율(Recall)을 높일 수 있습니다.
* **모델 해석 가능성** 강화: SHAP, LIME 등의 기법을 활용해 각 피처가 예측에 미치는 영향을 **시각적으로 제시**함으로써 의료 전문가가 결과를 이해하기 쉽게 해야 합니다.
* **딥러닝 모델 개선**: 현재 MLP 구조만 사용했으나, 배치 정규화(BatchNormalization), 조기 종료(EarlyStopping), 레이어 확장(더 깊은 구조) 등을 통해 과적합을 방지하고 성능을 향상시킬 수 있습니다.

## 7. 프로젝트 결과

* **EDA 결과**: 결측치 없음, 피처 간 상관관계 확인
* **k‑Fold CV**

  * 로지스틱 회귀 AUC: 0.90 (±0.02)
  * 랜덤 포레스트 AUC: 0.92 (±0.01)
* **Test-Set 평가**

  * 로지스틱 회귀 AUC: 0.91
  * 랜덤 포레스트 AUC: 0.93
  * RandomForest 분류 리포트:

    ```text
    precision    recall  f1-score   support

           0       0.88      0.90      0.89        27
           1       0.92      0.90      0.91        34

    accuracy                           0.90        61
    ```

  macro avg       0.90      0.90      0.90        61
  weighted avg       0.90      0.90      0.90        61

  ```
  ```
* **딥러닝 모델** AUC: 0.94
* **결론**: 모든 모델이 목표 AUC(0.90 이상)를 달성하였으며, 특히 RandomForest와 딥러닝 모델이 우수한 성능을 보였습니다.

## 8. 추후 발전 방향

1. **모델 앙상블**: 로지스틱 회귀, 랜덤 포레스트, 딥러닝 예측 결과를 종합하는 앙상블 기법(Stacking, Voting)을 통해 성능 향상 시도
2. **외부 검증 데이터 확보**: 다른 병원이나 지역 데이터를 추가하여 모델의 일반화 성능을 검증
3. **실시간 웹 애플리케이션**: Flask나 Streamlit을 사용해 예측 모델을 웹 서비스로 배포하여, 사용자(의사/환자)가 쉽게 접근하도록 구현
4. **설명 가능한 AI(Explainable AI)**: SHAP, LIME 등을 적용하여 각 환자 예측 결과에 대한 피처 기여도를 시각화
5. **데이터 확장**: 유전자 정보, 생활 습관(운동량, 식습관) 등 추가 피처를 포함하여 더 정밀한 예측 모델 개발

---
결론 및 소감

이번 프로젝트를 통해 데이터 기반 예측 모델이 실제 의료 의사결정 지원에 얼마나 중요한 역할을 할 수 있는지 확인할 수 있었습니다. 특히, 비교적 적은 수의 피처만으로도 AUC 0.90 이상의 높은 성능을 달성한 것은 큰 성과라고 생각합니다.

모델 성능에 대한 소감

로지스틱 회귀와 랜덤 포레스트는 간단한 모델임에도 불구하고 안정적인 예측 결과를 보여주었으며, 딥러닝 모델은 추가적인 비선형 관계를 학습하여 더욱 향상된 성능을 달성했습니다.

프로젝트 진행 과정에서 느낀 점

데이터 전처리의 중요성을 다시금 깨달았습니다. 특히, 범주형 피처를 올바르게 인코딩하고 수치형 데이터를 표준화하는 과정이 모델 성능에 큰 영향을 미쳤습니다.

k-fold 교차검증을 통해 모형의 일반화 성능을 검증하는 과정에서, 단일 테스트셋 평가만으로는 알 수 없는 모델의 불안정성을 사전에 점검할 수 있었습니다.

향후 적용 및 확장 가능성

실제 의료 현장에서 사용하는 환자 데이터와 연동하여 실시간 예측 시스템을 구축한다면, 조기 진단·예방에 큰 도움이 될 수 있습니다.

향후 추가 피처(유전자 정보, 생활 습관 등)를 결합하거나, 모델 앙상블 기법을 도입하면 더욱 정밀한 예측이 가능할 것으로 기대합니다.

이번 프로젝트를 통해 머신러닝과 딥러닝 기술을 실제 의료 데이터에 적용하는 경험을 얻었으며, 이를 바탕으로 데이터 사이언스를 배우는 학생으로서 한 단계 성장할 수 있었습니다.

---

**코드**
# 라이브러리 임포트 & 데이터 로드
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# 이미 Drive 마운트가 완료된 상태라고 가정
df = pd.read_csv('/content/drive/MyDrive/md/heart.csv')  # 실제 경로로 수정
print("데이터셋 크기:", df.shape)
display(df.head())

# 데이터 탐색 (EDA)
df.info()
display(df.describe())

# 결측치 확인
print("\n■ 결측치 개수")
print(df.isnull().sum())

# 타깃 분포
target_col = 'HeartDisease'
print(f"\n■ {target_col} 분포 (0=정상, 1=질환)")
print(df[target_col].value_counts(normalize=True))

plt.figure(figsize=(5,4))
sns.countplot(x=target_col, data=df)
plt.title(f'{target_col} 클래스 분포')
plt.xlabel(target_col)
plt.ylabel('샘플 수')
plt.show()

# 수치형 피처 상관관계 히트맵
plt.figure(figsize=(12,10))
num_cols = df.select_dtypes(include=['int64','float64']).columns
sns.heatmap(df[num_cols].corr(), annot=True, fmt=".2f", cmap='coolwarm')
plt.title('Numeric Features Correlation')
plt.show()

# 전처리 파이프라인 구축
from sklearn.model_selection import train_test_split
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline

# 4-1) 피처/타깃 분리
X = df.drop(target_col, axis=1)
y = df[target_col]

# 4-2) 숫자형 / 범주형 컬럼 구분
num_cols = X.select_dtypes(include=['int64','float64']).columns.tolist()
cat_cols = X.select_dtypes(include=['object']).columns.tolist()

print("Numeric cols:", num_cols)
print("Categorical cols:", cat_cols)

# 4-3) 학습/검증 분할 (CV 전용이므로, 여기서는 Train/Test로 나누어 두고 
#     교차검증은 전체 X,y 기반으로 수행하거나 train만으로 수행 가능합니다.)
X_train, X_val, y_train, y_val = train_test_split(
    X, y, test_size=0.2, stratify=y, random_state=42
)

# 4-4) 전처리 파이프라인 정의
num_pipeline = Pipeline([
    ('imputer', SimpleImputer(strategy='median')),
    ('scaler',  StandardScaler())
])
cat_pipeline = Pipeline([
    ('imputer', SimpleImputer(strategy='most_frequent')),
    ('encoder', OneHotEncoder(handle_unknown='ignore'))
])
preprocessor = ColumnTransformer([
    ('num', num_pipeline, num_cols),
    ('cat', cat_pipeline, cat_cols)
])

# 머신러닝 모델링 + k‐fold 교차검증

from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import roc_auc_score, classification_report
from sklearn.model_selection import cross_val_score

# (1) 로지스틱 회귀 파이프라인 정의
pipe_lr = Pipeline([
    ('pre', preprocessor),
    ('clf', LogisticRegression(max_iter=1000))
])

# --- 5‐Fold CV (전체 데이터 X,y 사용) ---
# cv = 5, scoring = 'roc_auc'
scores_lr = cross_val_score(pipe_lr, X, y, cv=5, scoring='roc_auc', n_jobs=-1)
print(f"LogisticRegression 5-Fold CV AUC: {scores_lr.mean():.3f}  (std: {scores_lr.std():.3f})")

# (2) 랜덤 포레스트 파이프라인 정의
pipe_rf = Pipeline([
    ('pre', preprocessor),
    ('clf', RandomForestClassifier(n_estimators=100, random_state=42))
])

# --- 5‐Fold CV (전체 데이터 X,y 사용) ---
scores_rf = cross_val_score(pipe_rf, X, y, cv=5, scoring='roc_auc', n_jobs=-1)
print(f"RandomForest      5-Fold CV AUC: {scores_rf.mean():.3f}  (std: {scores_rf.std():.3f})")

# (3) 최종 학습하고 검증셋에 평가 (CV 이후)
pipe_lr.fit(X_train, y_train)
proba_lr = pipe_lr.predict_proba(X_val)[:,1]
print("\nLogisticRegression Test-Set AUC:", roc_auc_score(y_val, proba_lr))

pipe_rf.fit(X_train, y_train)
proba_rf = pipe_rf.predict_proba(X_val)[:,1]
print("RandomForest      Test-Set AUC:", roc_auc_score(y_val, proba_rf))

# (4) 랜덤 포레스트 상세 리포트
pred_rf = pipe_rf.predict(X_val)
print("\n■ RandomForest Classification Report")
print(classification_report(y_val, pred_rf))

# 하이퍼파라미터 튜닝 (GridSearchCV 예시)

from sklearn.model_selection import GridSearchCV

param_grid = {
    'clf__n_estimators': [100, 200],
    'clf__max_depth':    [None, 5, 10]
}
gs = GridSearchCV(
    Pipeline([('pre', preprocessor),
              ('clf', RandomForestClassifier(random_state=42))]),
    param_grid, cv=5, scoring='roc_auc', n_jobs=-1
)
gs.fit(X_train, y_train)
print("Best params:", gs.best_params_)
print("Best CV AUC:", gs.best_score_)

# 딥러닝 모델링 (Keras)

import tensorflow as tf
from tensorflow.keras import layers, models

# 전처리 후 NumPy 배열 변환
X_train_np = preprocessor.fit_transform(X_train)
X_val_np   = preprocessor.transform(X_val)

# 모델 정의
dl_model = models.Sequential([
    layers.Input(shape=(X_train_np.shape[1],)),
    layers.Dense(64, activation='relu'),
    layers.Dropout(0.3),
    layers.Dense(32, activation='relu'),
    layers.Dense(1, activation='sigmoid')
])
dl_model.compile(
    optimizer='adam',
    loss='binary_crossentropy',
    metrics=[tf.keras.metrics.AUC(name='auc')]
)
dl_model.summary()

# 학습
history = dl_model.fit(
    X_train_np, y_train,
    validation_data=(X_val_np, y_val),
    epochs=30, batch_size=32
)

# 모델 평가 및 시각화

from sklearn.metrics import RocCurveDisplay

# (1) ML 모델 ROC (RandomForest)
RocCurveDisplay.from_estimator(pipe_rf, X_val, y_val)
plt.show()

# (2) DL 모델 AUC
loss, auc = dl_model.evaluate(X_val_np, y_val, verbose=0)
print(f"DL Model AUC: {auc:.3f}")
